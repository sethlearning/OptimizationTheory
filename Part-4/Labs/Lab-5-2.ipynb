{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Обучение нейрона (VPL)\n","\n","Тип работы:  Индивидуальная работа\n","\n","Ваша задача - запрограммировать методы класса Logneuron с использованием правила Видроу-Хоффа так, чтобы нейрон смог обучиться на внешних данных моделировать булевы операции...\n","\n","Для обучения нейрона следует использовать алгоритм, который приведен в уроке 6.6. Обучение нейрона с использованием градиентного спуска (ВИДЕО).\n","\n","\n","ВХОД для ИНИЦИАЛИЗАЦИИ ОБЪЕКТА:\n","\n","```python\n","# num_features - размерность входа в нейрон (без учета нейрона сдвига)\n","\n","# eta, t_max - коэфф-т обучения нейрона и максимальное кол-во шагов обучения\n","\n","# обучение self.w, self.b на выборке X с метками y\n","def fit(self, X, y, random_state=42):\n","   pass\n","\n","# прогноз модели на выборке X\n","def predict(self, X):\n","   ym = ...\n","   return ym\n","```\n","\n","ПРИМЕР.\n","\n","В качестве данных будет использоваться выборка данных для задачи классификации цветков Ириса с помощь функции из sklearn.datasets.\n","\n","`num_features=4`\n","\n","\n","Для входных параметров `eta=0.1, t_max=10` \n","\n","Должна быть достигнута точность классификации на тестовой выборке >= 0,71"]},{"cell_type":"code","execution_count":265,"metadata":{"id":"yRrftJLlVuCB"},"outputs":[],"source":["import numpy as np\n","\n","# этот модуль программирует обучающийся !!!\n","\n","class Logneuron:\n","    \n","    # инициализация объекта нейрон\n","    # num_features - размерность входа в нейрон (без учета нейрона сдвига)\n","    # eta, t_max - коэфф-т обучения нейрона и максимальное кол-во шагов обучения\n","    def __init__(self, num_features, eta, t_max, random_state=42):\n","        np.random.seed(random_state)\n","        self.b = 0\n","        self.eta = eta\n","        self.w = np.random.random(num_features) - 0.5\n","        self.t_max = t_max\n","        self.t = 0\n","    \n","    # обучение self.w, self.b на выборке X с метками y\n","    def fit(self, X, y, random_state=42):\n","        # np.random.seed(random_state)\n","        # ... обучение нейрона на выборке X с метками y\n","        print(f'Prediction: {self.predict(X=X)}')\n","        for step in range(self.t_max):\n","            print(f'\\nStep: {step}')\n","            u = self.getValues(X=X)\n","            print(f'u: {np.round(u, 6)}')\n","\n","            ym = self.getActivationValues(u=u)\n","            print(f'ym: {np.round(ym, 6)}')\n","\n","            diff = self.getDifference(y=y, ym=ym)\n","            print(f'Diff: {np.round(diff, 6)}')\n","\n","            grad = self.getGradient(X=X, diff=diff)\n","            print(f'Gradient: {grad}')\n","\n","            self.b += self.eta * grad[0]\n","            self.w += self.eta * grad[1:]\n","            print(f'New W: {np.round((self.b, *self.w), 6)}')\n","            print(f'New prediction: {self.predict(X=X)}')\n","        # for step in range(self.t_max):\n","        #     ym = []\n","        #     ydiff = []\n","        #     gr = []\n","        #     for i in range(X.shape[0]):\n","        #         res = self.b * 1.0\n","        #         for j in range(X.shape[1]):\n","        #             res += self.w * X[i, j]\n","        #         ym.append(self.sigmoid(res))\n","        #         ydiff.append(y[i] - ym[i])\n","        #         ydiffn = np.array(ydiff)\n","\n","        #     ydiffsum = np.sum(ydiffn)\n","        #     self.b = self.b + self.eta * 2 * ydiffsum / (X.shape[0])\n","\n","        #     for j in range(X.shape[1]):\n","        #         res = 0\n","        #         for i in range(X.shape[0]):\n","        #             res += ydiffn[i] * X[i, j]\n","        #         gr.append(2*res/(X.shape[0]))\n","        #     grn = np.array(gr)\n","        #     self.w = self.w + self.eta * grn\n","\n","    # def get_class(self, y):\n","    #     return 1 if y >= 0.5 else 0\n","\n","    def get_class(self, ym):\n","        return np.array([1 if x >=0.5 else 0 for x in ym])\n","        # label = []\n","        # # ... определение метки класса (0 или 1) по выходу нейросети ym\n","        # for i in range(len(ym)):\n","        #     if ym[i] >= 0.5:\n","        #         label.append(1)\n","        #     else:\n","        #         label.append(0)\n","        # return label\n","    \n","    # # прогноз модели на выборке X\n","    # def predict(self, X):\n","    #     ym = None\n","        \n","    #     # ... программируем прогноз модели ...\n","    #     label = self.get_class(ym)\n","    #     return label\n","\n","    # прогноз модели на выборке X\n","    def predict(self, X):\n","        ym = self.getActivationValues(self.getValues(X=X))\n","        return self.get_class(ym=ym)\n","        # ym = []\n","        # for i in range(X.shape[0]):\n","        #     res = self.b * 1.0\n","        #     for j in range(X.shape[1]):\n","        #         res += self.w[j] * X[i, j]\n","        #     ym.append(self.sigmoid(res))\n","        # label = self.get_class(ym)\n","        # return label\n","\n","        # # ym = np.sign(self.w @ np.array([1.0, *X]))\n","        # return ym\n","\n","    def getGradient1(self, X, diff):\n","        xlines = X.shape[0]\n","        xcolumns = X.shape[1]\n","        result = [2 * np.sum(diff) / xlines]\n","        for j in range(xcolumns):\n","            r = 0.0\n","            for i in range(xlines):\n","                r += diff[i] * X[i, j]\n","            result.append(2 * r / xlines)\n","        return np.array(result)\n","\n","    def getGradient(self, X, diff):\n","        xlines = X.shape[0]\n","        xcolumns = X.shape[1]\n","        result = [np.sum(diff)]\n","        for j in range(xcolumns):\n","            xc = np.array(X[:,j])\n","            result.append(diff @ xc)\n","        return np.array(result) * 2 / xlines\n","\n","    def getDifference(self, y, ym):\n","        y = np.array(y)\n","        ym = np.array(ym)\n","        return y - ym\n","\n","    def getActivationValues1(self, u):\n","        r = []\n","        for i in range(u.shape[0]):\n","            r.append(1 / (1 + np.exp(-u[i])))\n","        return np.array(r)\n","\n","    def getActivationValues(self, u):\n","        return 1 / (1 + np.exp(-u))\n","\n","    def getValues1(self, X):\n","        xlines = X.shape[0]\n","        xcolumns = X.shape[1]\n","        us = []\n","        for i in range(xlines):\n","            r = self.b * 1.0\n","            for j in range(xcolumns):\n","                r += X[i,j] * self.w[j]\n","            us.append(r)\n","        usn = np.array(us)\n","        return usn\n","\n","    def getValues(self, X):\n","        xlines = X.shape[0]\n","        us = []\n","        for i in range(xlines):\n","            xi = np.array(X[i])\n","            us.append(self.b + xi @ self.w)\n","        return np.array(us)\n","\n","    def selftest(self, case=3):\n","        print(f'NumFeatures: {self.w.shape[0]} Eta: {self.eta}, TMax: {self.t_max}')\n","        print(f'W: {np.round((self.b, *self.w), 6)}')\n","\n","        X = np.array([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9]])\n","        print(f'X: {X}')\n","        y = np.array([0, 0, 1])\n","        print(f'y: {y}')\n","\n","        values = self.getValues(X=X)\n","        print(f'Values  : {np.round(values, 6)}')\n","        # valuesnp = self.getValuesNP(X=X)\n","        # print(f'ValuesNP: {np.round(valuesnp, 6)}')\n","\n","        activationValues = self.getActivationValues(u=values)\n","        print(f'ActivationValues  : {np.round(activationValues, 6)}')\n","        # activationValuesNP = self.getActivationValuesNP(u=values)\n","        # print(f'ActivationValuesNP: {np.round(activationValuesNP, 6)}')\n","\n","        difference = self.getDifference(y=y, ym=activationValues)\n","        print(f'Difference: {np.round(difference, 6)}')\n","        # print(f'Sum(Difference): {np.sum(difference)}')\n","\n","        gradient = self.getGradient(X=X, diff=difference)\n","        print(f'Gradient:  {gradient}')\n","\n","        # gradient1 = self.getGradient1(X=X, diff=difference)\n","        # print(f'Gradient1: {gradient1}')\n","\n","        prediction = self.predict(X)\n","        print(f'Prediction: {prediction}')\n","\n","        # print(X[:,0])\n","        # print(difference @ X[:,0])\n","\n","        print('\\nFIT:')\n","        self.fit(X=X, y=y)"]},{"cell_type":"markdown","metadata":{},"source":["#### Test"]},{"cell_type":"code","execution_count":266,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["NumFeatures: 3 Eta: 0.1, TMax: 50\n","W: [ 0.       -0.12546   0.450714  0.231994]\n","X: [[0.1 0.2 0.3]\n"," [0.4 0.5 0.6]\n"," [0.7 0.8 0.9]]\n","y: [0 0 1]\n","Values  : [0.147195 0.31437  0.481544]\n","ActivationValues  : [0.536732 0.577951 0.618112]\n","Difference: [-0.536732 -0.577951  0.381888]\n","Gradient:  [-0.4885309  -0.01168835 -0.06054144 -0.10939453]\n","Prediction: [1 1 1]\n","\n","FIT:\n","Prediction: [1 1 1]\n","\n","Step: 0\n","u: [0.147195 0.31437  0.481544]\n","ym: [0.536732 0.577951 0.618112]\n","Diff: [-0.536732 -0.577951  0.381888]\n","Gradient: [-0.4885309  -0.01168835 -0.06054144 -0.10939453]\n","New W: [-0.048853 -0.126629  0.44466   0.221054]\n","New prediction: [1 1 1]\n","\n","Step: 1\n","u: [0.093732 0.255458 0.417184]\n","ym: [0.523416 0.563519 0.602809]\n","Diff: [-0.523416 -0.563519  0.397191]\n","Gradient: [-4.59829772e-01  1.89442840e-04 -4.57935344e-02 -9.17765116e-02]\n","New W: [-0.094836 -0.12661   0.440081  0.211877]\n","New prediction: [1 1 1]\n","\n","Step: 2\n","u: [0.044082 0.201687 0.359291]\n","ym: [0.511019 0.550251 0.588869]\n","Diff: [-0.511019 -0.550251  0.411131]\n","Gradient: [-0.43342596  0.01105962 -0.03228298 -0.07562558]\n","New W: [-0.138179 -0.125504  0.436853  0.204314]\n","New prediction: [0 1 1]\n","\n","Step: 3\n","u: [-0.002064  0.152635  0.307334]\n","ym: [0.499484 0.538085 0.576234]\n","Diff: [-0.499484 -0.538085  0.423766]\n","Gradient: [-0.40920197  0.02096914 -0.01995105 -0.06087125]\n","New W: [-0.179099 -0.123407  0.434857  0.198227]\n","New prediction: [0 1 1]\n","\n","Step: 4\n","u: [-0.045     0.107903  0.260807]\n","ym: [0.488752 0.52695  0.564835]\n","Diff: [-0.488752 -0.52695   0.435165]\n","Gradient: [-0.38702413  0.02997381 -0.0087286  -0.04743101]\n","New W: [-0.217801 -0.12041   0.433985  0.193484]\n","New prediction: [0 1 1]\n","\n","Step: 5\n","u: [-0.085     0.067118  0.219235]\n","ym: [0.478763 0.516773 0.55459 ]\n","Diff: [-0.478763 -0.516773  0.44541 ]\n","Gradient: [-0.36675082  0.03813415  0.00145907 -0.03521601]\n","New W: [-0.254476 -0.116596  0.43413   0.189962]\n","New prediction: [0 1 1]\n","\n","Step: 6\n","u: [-0.122321  0.029928  0.182177]\n","ym: [0.469458 0.507481 0.545419]\n","Diff: [-0.469458 -0.507481  0.454581]\n","Gradient: [-0.3482386   0.04551238  0.01068852 -0.02413534]\n","New W: [-0.2893   -0.112045  0.435199  0.187549]\n","New prediction: [0 0 1]\n","\n","Step: 7\n","u: [-0.1572   -0.003989  0.149222]\n","ym: [0.460781 0.499003 0.537236]\n","Diff: [-0.460781 -0.499003  0.462764]\n","Gradient: [-0.33134653  0.05217025  0.01903559 -0.01409906]\n","New W: [-0.322435 -0.106828  0.437103  0.186139]\n","New prediction: [0 0 1]\n","\n","Step: 8\n","u: [-0.189855 -0.034931  0.119993]\n","ym: [0.452678 0.491268 0.529962]\n","Diff: [-0.452678 -0.491268  0.470038]\n","Gradient: [-0.31593909  0.05816754  0.02657363 -0.00502027]\n","New W: [-0.354029 -0.101011  0.43976   0.185637]\n","New prediction: [0 0 1]\n","\n","Step: 9\n","u: [-0.220487 -0.063171  0.094145]\n","ym: [0.445101 0.484213 0.523519]\n","Diff: [-0.445101 -0.484213  0.476481]\n","Gradient: [-0.30188795  0.06356115  0.03337236  0.00318356]\n","New W: [-0.384218 -0.094655  0.443097  0.185955]\n","New prediction: [0 0 1]\n","\n","Step: 10\n","u: [-0.249277 -0.088958  0.071362]\n","ym: [0.438001 0.477775 0.517833]\n","Diff: [-0.438001 -0.477775  0.482167]\n","Gradient: [-0.28907305  0.0684045   0.03949719  0.01058989]\n","New W: [-0.413125 -0.087815  0.447047  0.187014]\n","New prediction: [0 0 1]\n","\n","Step: 11\n","u: [-0.276393 -0.112518  0.051356]\n","ym: [0.431338 0.4719   0.512836]\n","Diff: [-0.431338 -0.4719    0.487164]\n","Gradient: [-0.277383    0.07274726  0.04500897  0.01727067]\n","New W: [-0.440863 -0.08054   0.451548  0.188741]\n","New prediction: [0 0 1]\n","\n","Step: 12\n","u: [-0.301985 -0.13406   0.033865]\n","ym: [0.425072 0.466535 0.508465]\n","Diff: [-0.425072 -0.466535  0.491535]\n","Gradient: [-0.26671513  0.07663533  0.04996382  0.02329231]\n","New W: [-0.467535 -0.072876  0.456544  0.191071]\n","New prediction: [0 0 1]\n","\n","Step: 13\n","u: [-0.326192 -0.153771  0.018651]\n","ym: [0.419167 0.461633 0.504663]\n","Diff: [-0.419167 -0.461633  0.495337]\n","Gradient: [-0.2569753   0.08011083  0.0544133   0.02871577]\n","New W: [-0.493232 -0.064865  0.461986  0.193942]\n","New prediction: [0 0 1]\n","\n","Step: 14\n","u: [-0.349139 -0.17182   0.005499]\n","ym: [0.413591 0.45715  0.501375]\n","Diff: [-0.413591 -0.45715   0.498625]\n","Gradient: [-0.24807752  0.0832123   0.05840455  0.0335968 ]\n","New W: [-0.51804  -0.056544  0.467826  0.197302]\n","New prediction: [0 0 0]\n","\n","Step: 15\n","u: [-0.370939 -0.188363 -0.005788]\n","ym: [0.408314 0.453048 0.498553]\n","Diff: [-0.408314 -0.453048  0.501447]\n","Gradient: [-0.23994344  0.08597487  0.06198053  0.03798619]\n","New W: [-0.542034 -0.047946  0.474024  0.201101]\n","New prediction: [0 0 0]\n","\n","Step: 16\n","u: [-0.391694 -0.20354  -0.015387]\n","ym: [0.40331  0.44929  0.496153]\n","Diff: [-0.40331  -0.44929   0.503847]\n","Gradient: [-0.23250184  0.08843051  0.06518033  0.04193014]\n","New W: [-0.565285 -0.039103  0.480542  0.205294]\n","New prediction: [0 0 0]\n","\n","Step: 17\n","u: [-0.411498 -0.217479 -0.023459]\n","ym: [0.398553 0.445844 0.494136]\n","Diff: [-0.398553 -0.445844  0.505864]\n","Gradient: [-0.22568807  0.09060824  0.06803944  0.04547063]\n","New W: [-0.587853 -0.030043  0.487346  0.209841]\n","New prediction: [0 0 0]\n","\n","Step: 18\n","u: [-0.430436 -0.230293 -0.03015 ]\n","ym: [0.394022 0.44268  0.492463]\n","Diff: [-0.394022 -0.44268   0.507537]\n","Gradient: [-0.21944351  0.0925344   0.07059005  0.0486457 ]\n","New W: [-0.609798 -0.020789  0.494405  0.214705]\n","New prediction: [0 0 0]\n","\n","Step: 19\n","u: [-0.448584 -0.242088 -0.035591]\n","ym: [0.389697 0.439772 0.491103]\n","Diff: [-0.389697 -0.439772  0.508897]\n","Gradient: [-0.21371506  0.09423285  0.07286134  0.05148983]\n","New W: [-0.631169 -0.011366  0.501691  0.219854]\n","New prediction: [0 0 0]\n","\n","Step: 20\n","u: [-0.466011 -0.252957 -0.039903]\n","ym: [0.385561 0.437096 0.490025]\n","Diff: [-0.385561 -0.437096  0.509975]\n","Gradient: [-0.20845465  0.0957252   0.07487973  0.05403427]\n","New W: [-0.652015 -0.001793  0.509179  0.225258]\n","New prediction: [0 0 0]\n","\n","Step: 21\n","u: [-0.482781 -0.262988 -0.043195]\n","ym: [0.381596 0.434629 0.489203]\n","Diff: [-0.381596 -0.434629  0.510797]\n","Gradient: [-0.20361874  0.09703104  0.07666917  0.05630729]\n","New W: [-0.672377  0.00791   0.516846  0.230888]\n","New prediction: [0 0 0]\n","\n","Step: 22\n","u: [-0.49895  -0.272256 -0.045563]\n","ym: [0.377788 0.432353 0.488611]\n","Diff: [-0.377788 -0.432353  0.511389]\n","Gradient: [-0.19916794  0.09816809  0.0782513   0.0583345 ]\n","New W: [-0.692293  0.017727  0.524671  0.236722]\n","New prediction: [0 0 0]\n","\n","Step: 23\n","u: [-0.51457  -0.280834 -0.047098]\n","ym: [0.374123 0.430249 0.488228]\n","Diff: [-0.374123 -0.430249  0.511772]\n","Gradient: [-0.19506659  0.0991524   0.07964574  0.06013908]\n","New W: [-0.7118    0.027642  0.532636  0.242736]\n","New prediction: [0 0 0]\n","\n","Step: 24\n","u: [-0.529688 -0.288784 -0.04788 ]\n","ym: [0.37059  0.428302 0.488032]\n","Diff: [-0.37059  -0.428302  0.511968]\n","Gradient: [-0.19128244  0.0999985   0.08087025  0.06174201]\n","New W: [-0.730928  0.037642  0.540723  0.24891 ]\n","New prediction: [0 0 0]\n","\n","Step: 25\n","u: [-0.544346 -0.296164 -0.047982]\n","ym: [0.367177 0.426495 0.488007]\n","Diff: [-0.367177 -0.426495  0.511993]\n","Gradient: [-0.18778626  0.10071953  0.08194091  0.06316228]\n","New W: [-0.749707  0.047714  0.548917  0.255226]\n","New prediction: [0 0 0]\n","\n","Step: 26\n","u: [-0.558584 -0.303027 -0.04747 ]\n","ym: [0.363875 0.424818 0.488135]\n","Diff: [-0.363875 -0.424818  0.511865]\n","Gradient: [-0.18455163  0.10132743  0.08287227  0.06441711]\n","New W: [-0.768162  0.057846  0.557204  0.261668]\n","New prediction: [0 0 0]\n","\n","Step: 27\n","u: [-0.572436 -0.309421 -0.046405]\n","ym: [0.360675 0.423256 0.488401]\n","Diff: [-0.360675 -0.423256  0.511599]\n","Gradient: [-0.18155459  0.10183298  0.08367752  0.06552206]\n","New W: [-0.786317  0.06803   0.565572  0.26822 ]\n","New prediction: [0 0 0]\n","\n","Step: 28\n","u: [-0.585934 -0.315388 -0.044841]\n","ym: [0.357568 0.4218   0.488792]\n","Diff: [-0.357568 -0.4218    0.511208]\n","Gradient: [-0.17877346  0.10224595  0.08436861  0.06649126]\n","New W: [-0.804195  0.078254  0.574009  0.274869]\n","New prediction: [0 0 0]\n","\n","Step: 29\n","u: [-0.599107 -0.320967 -0.042827]\n","ym: [0.354548 0.42044  0.489295]\n","Diff: [-0.354548 -0.42044   0.510705]\n","Gradient: [-0.1761886   0.10257522  0.08495635  0.06733749]\n","New W: [-0.821814  0.088512  0.582505  0.281603]\n","New prediction: [0 0 0]\n","\n","Step: 30\n","u: [-0.611981 -0.326195 -0.040409]\n","ym: [0.351608 0.419167 0.489899]\n","Diff: [-0.351608 -0.419167  0.510101]\n","Gradient: [-0.17378223  0.10282879  0.08545057  0.06807235]\n","New W: [-0.839192  0.098795  0.59105   0.28841 ]\n","New prediction: [0 0 0]\n","\n","Step: 31\n","u: [-0.624579 -0.331103 -0.037627]\n","ym: [0.348741 0.417972 0.490594]\n","Diff: [-0.348741 -0.417972  0.509406]\n","Gradient: [-0.1715382   0.10301397  0.08586015  0.06870633]\n","New W: [-0.856346  0.109096  0.599636  0.295281]\n","New prediction: [0 0 0]\n","\n","Step: 32\n","u: [-0.636925 -0.335721 -0.034517]\n","ym: [0.345942 0.416849 0.491372]\n","Diff: [-0.345942 -0.416849  0.508628]\n","Gradient: [-0.1694419   0.10313734  0.08619315  0.06924896]\n","New W: [-0.87329   0.11941   0.608255  0.302206]\n","New prediction: [0 0 0]\n","\n","Step: 33\n","u: [-0.649036 -0.340075 -0.031114]\n","ym: [0.343207 0.415791 0.492222]\n","Diff: [-0.343207 -0.415791  0.507778]\n","Gradient: [-0.16748008  0.10320489  0.08645688  0.06970887]\n","New W: [-0.890038  0.12973   0.616901  0.309177]\n","New prediction: [0 0 0]\n","\n","Step: 34\n","u: [-0.660932 -0.34419  -0.027447]\n","ym: [0.34053  0.414792 0.493139]\n","Diff: [-0.34053  -0.414792  0.506861]\n","Gradient: [-0.16564073  0.10322205  0.08665798  0.07009391]\n","New W: [-0.906602  0.140052  0.625566  0.316186]\n","New prediction: [0 0 0]\n","\n","Step: 35\n","u: [-0.672628 -0.348086 -0.023545]\n","ym: [0.337909 0.413847 0.494114]\n","Diff: [-0.337909 -0.413847  0.505886]\n","Gradient: [-0.16391293  0.10319375  0.08680246  0.07041117]\n","New W: [-0.922993  0.150372  0.634247  0.323227]\n","New prediction: [0 0 0]\n","\n","Step: 36\n","u: [-0.684139 -0.351785 -0.019431]\n","ym: [0.335338 0.41295  0.495142]\n","Diff: [-0.335338 -0.41295   0.504858]\n","Gradient: [-0.16228681  0.10312445  0.08689577  0.07066709]\n","New W: [-0.939222  0.160684  0.642936  0.330294]\n","New prediction: [0 0 0]\n","\n","Step: 37\n","u: [-0.695478 -0.355304 -0.01513 ]\n","ym: [0.332816 0.412097 0.496218]\n","Diff: [-0.332816 -0.412097  0.503782]\n","Gradient: [-0.16075339  0.10301821  0.08694288  0.07086754]\n","New W: [-0.955297  0.170986  0.651631  0.33738 ]\n","New prediction: [0 0 0]\n","\n","Step: 38\n","u: [-0.706658 -0.358659 -0.01066 ]\n","ym: [0.330338 0.411284 0.497335]\n","Diff: [-0.330338 -0.411284  0.502665]\n","Gradient: [-0.15930453  0.10287871  0.08694826  0.07101781]\n","New W: [-0.971228  0.181274  0.660325  0.344482]\n","New prediction: [0 0 0]\n","\n","Step: 39\n","u: [-0.717691 -0.361866 -0.006042]\n","ym: [0.327902 0.410508 0.49849 ]\n","Diff: [-0.327902 -0.410508  0.50151 ]\n","Gradient: [-0.15793285  0.10270929  0.086916    0.07112272]\n","New W: [-0.987021  0.191545  0.669017  0.351595]\n","New prediction: [0 0 0]\n","\n","Step: 40\n","u: [-0.728585 -0.364938 -0.001291]\n","ym: [0.325505 0.409765 0.499677]\n","Diff: [-0.325505 -0.409765  0.500323]\n","Gradient: [-0.15663163  0.10251297  0.0868498   0.07118664]\n","New W: [-1.002684  0.201796  0.677702  0.358713]\n","New prediction: [0 0 1]\n","\n","Step: 41\n","u: [-0.73935  -0.367887  0.003577]\n","ym: [0.323146 0.409052 0.500894]\n","Diff: [-0.323146 -0.409052  0.499106]\n","Gradient: [-0.15539478  0.10229251  0.08675303  0.07121355]\n","New W: [-1.018224  0.212025  0.686377  0.365835]\n","New prediction: [0 0 1]\n","\n","Step: 42\n","u: [-0.749995 -0.370724  0.008547]\n","ym: [0.320822 0.408366 0.502137]\n","Diff: [-0.320822 -0.408366  0.497863]\n","Gradient: [-0.15421677  0.1020504   0.08662873  0.07120705]\n","New W: [-1.033645  0.222231  0.69504   0.372955]\n","New prediction: [0 0 1]\n","\n","Step: 43\n","u: [-0.760528 -0.37346   0.013608]\n","ym: [0.318532 0.407705 0.503402]\n","Diff: [-0.318532 -0.407705  0.496598]\n","Gradient: [-0.15309259  0.10178892  0.08647966  0.0711704 ]\n","New W: [-1.048955  0.232409  0.703688  0.380072]\n","New prediction: [0 0 1]\n","\n","Step: 44\n","u: [-0.770954 -0.376103  0.018748]\n","ym: [0.316273 0.407067 0.504687]\n","Diff: [-0.316273 -0.407067  0.495313]\n","Gradient: [-0.15201767  0.10151012  0.08630835  0.07110658]\n","New W: [-1.064156  0.24256   0.712319  0.387183]\n","New prediction: [0 0 1]\n","\n","Step: 45\n","u: [-0.781282 -0.378663  0.023956]\n","ym: [0.314044 0.406449 0.505989]\n","Diff: [-0.314044 -0.406449  0.494011]\n","Gradient: [-0.15098787  0.10121587  0.08611708  0.07101829]\n","New W: [-1.079255  0.252682  0.720931  0.394285]\n","New prediction: [0 0 1]\n","\n","Step: 46\n","u: [-0.791515 -0.381146  0.029223]\n","ym: [0.311843 0.40585  0.507305]\n","Diff: [-0.311843 -0.40585   0.492695]\n","Gradient: [-0.14999942  0.10090786  0.08590791  0.07090797]\n","New W: [-1.094255  0.262773  0.729521  0.401376]\n","New prediction: [0 0 1]\n","\n","Step: 47\n","u: [-0.801661 -0.38356   0.034541]\n","ym: [0.30967  0.405269 0.508634]\n","Diff: [-0.30967  -0.405269  0.491366]\n","Gradient: [-0.1490489   0.10058763  0.08568274  0.07077785]\n","New W: [-1.10916   0.272832  0.73809   0.408453]\n","New prediction: [0 0 1]\n","\n","Step: 48\n","u: [-0.811723 -0.38591   0.039902]\n","ym: [0.307523 0.404702 0.509974]\n","Diff: [-0.307523 -0.404702  0.490026]\n","Gradient: [-0.1481332   0.10025658  0.08544326  0.07062994]\n","New W: [-1.123973  0.282857  0.746634  0.415516]\n","New prediction: [0 0 1]\n","\n","Step: 49\n","u: [-0.821706 -0.388204  0.045299]\n","ym: [0.305402 0.40415  0.511323]\n","Diff: [-0.305402 -0.40415   0.488677]\n","Gradient: [-0.1472495   0.09991598  0.08519103  0.07046608]\n","New W: [-1.138698  0.292849  0.755153  0.422563]\n","New prediction: [0 0 1]\n"]}],"source":["# 3\n","a = Logneuron(num_features=3, eta=0.1, t_max=50, random_state=42)\n","a.selftest()"]},{"cell_type":"code","execution_count":267,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[1, 2, 3, 4, 5, 6, 4, 5, 6, 4, 5, 6]\n","[13 17 21]\n"]}],"source":["l1 = [1,2,3]\n","l2 = [4,5,6]\n","k=3\n","print(l1 + k*l2)\n","\n","n1 = np.array(l1)\n","n2 = np.array(l2)\n","print(n1 + k*n2)\n"]},{"cell_type":"code","execution_count":268,"metadata":{},"outputs":[{"data":{"text/plain":["array([1, 0, 1])"]},"execution_count":268,"metadata":{},"output_type":"execute_result"}],"source":["# predicate = \n","int((1>=0.5))\n","\n","aa = np.array([0.5, 0.3, 0.7])\n","# np.array((aa >=0.5), dtype=int)\n","np.array([1 if x >=0.5 else 0 for x in aa])"]},{"cell_type":"code","execution_count":269,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'difference' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn [269], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m difference\n","\u001b[1;31mNameError\u001b[0m: name 'difference' is not defined"]}],"source":["difference"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNYDyeMQ5OTUETCO8xEozWt","provenance":[]},"kernelspec":{"display_name":"Python 3.11.0 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"vscode":{"interpreter":{"hash":"5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"}}},"nbformat":4,"nbformat_minor":0}
